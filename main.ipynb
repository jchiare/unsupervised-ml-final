{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description / Topic Modelling\n",
    "\n",
    "We will use a unsupervised machine learning algorithm to categorize Customer Support help center articles - also known as **Topic Modelling**. The problem we are trying to solve is that searching a few hundred help center article has a better user experience when you can use tags to find articles that matter to you. This will also be used for search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Gather data\n",
    "\n",
    "\n",
    "I'll create a function that will download the text from a specific help center that uses Zendesk (A SaaS). We check if the data already exists at `data/articles.csv`, if it does then we don't get the data again. \n",
    "\n",
    "Since each help center is related to one specific business, we will only process one companies help center instead of processing many help center. This will allow our Topic Modelling model(s) to be more accurate for each specific business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/articles.csv already exists. Skipping data collection.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def fetch_articles():\n",
    "    url = \"https://support.amboss.com/api/v2/help_center/en-us/articles?per_page=100\"\n",
    "    all_articles = []\n",
    "\n",
    "    while url:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        all_articles.extend(data['articles'])\n",
    "        url = data.get('next_page')\n",
    "\n",
    "    return all_articles\n",
    "\n",
    "def save_articles_to_csv(articles, filename):\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "file_path = 'data/articles.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    articles = fetch_articles()\n",
    "    save_articles_to_csv(articles, file_path)\n",
    "    print(f\"Articles saved to {file_path}\")\n",
    "else:\n",
    "    print(f\"File {file_path} already exists. Skipping data collection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Identify an Unsupervised Learning Problem\n",
    "\n",
    "For categorizing / labelling a relatively large amount (100+) customer support help center articles, we will use Topic Modelling (and most likely Latent Dirichlet Allocation) as the unsupervised learning algorithm because we don't have labels on the existing customer support help center articles. In addition, we are an external team, so we won't have the knowledge needed to manually label the data. Some other reasons we will use that unsupervised learning algorithm:\n",
    "* It can discover latent features well within a collection of documents.\n",
    "* Topic Modelling works well with unstructured text.\n",
    "* It can handle new and update help center articles well - since the information on a support help center changes often, we want a scalable solution. \n",
    "* It is also flexible, and will be able to find latent features in any new informmation that is provided in the help center articles. \n",
    "* It can condense the high dimensionaility of words into a lower dimension topics, which will make it easier to analyze the overall themes.\n",
    "\n",
    "Using a supervised machine learning algorithm is not ideal because we don't have labelled data and we want this solution to be scalable. We want to be able to handle new topics without needing to re-fit or label our data - otherwise a supervised algorithm will be considered overfit if we don't re-train the model when new topics or themes in the support help center are introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - EDA\n",
    "\n",
    "\n",
    "\n",
    "â€¢ Describe the factors or components that make up the dataset (The \"factors\" here are\n",
    "called \"features\" in the machine learning term. These factors are often columns in the\n",
    "tabulated data). For each factor, use a box-plot, scatter plot, histogram, etc., to\n",
    "describe the data distribution as appropriate.\n",
    "â€¢ Describe correlations between different factors of the dataset and justify your\n",
    "assumption that they are correlated or not correlated. You may use numeric or\n",
    "qualitative/graphical analysis for this step.\n",
    "â€¢ Determine if any data needs to be transformed. For example, if you're planning on\n",
    "using an SVM method for prediction, you may need to normalize or scale the data if\n",
    "there is a considerable difference in the range of the data.\n",
    "â€¢ Using your hypothesis, indicate if it's likely that you should transform data, such as\n",
    "using a log transform or other transformation of the dataset.\n",
    "â€¢ You should determine if your data has outliers or needs to be cleaned in any way.\n",
    "Are there missing data values for specific factors? How will you handle the data\n",
    "cleaning? Will you discard, interpolate or otherwise substitute data values?\n",
    "â€¢ If you believe that specific factors will be more important than others in your\n",
    "analysis, you should mention which and why. You will use this to confirm your\n",
    "intuitions in your final write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 26)\n",
      "Number of articles: 165\n",
      "Column names:\n",
      "['id', 'url', 'html_url', 'author_id', 'comments_disabled', 'draft', 'promoted', 'position', 'vote_sum', 'vote_count', 'section_id', 'created_at', 'updated_at', 'name', 'title', 'source_locale', 'locale', 'outdated', 'outdated_locales', 'edited_at', 'user_segment_id', 'permission_group_id', 'content_tag_ids', 'label_names', 'body', 'user_segment_ids']\n",
      "First two rows of the dataset:\n",
      "               id                                                url  \\\n",
      "0  23699429949841  https://amboss.zendesk.com/api/v2/help_center/...   \n",
      "1  16195168657809  https://amboss.zendesk.com/api/v2/help_center/...   \n",
      "\n",
      "                                            html_url     author_id  \\\n",
      "0  https://support.amboss.com/hc/en-us/articles/2...  403291139191   \n",
      "1  https://support.amboss.com/hc/en-us/articles/1...  380858881411   \n",
      "\n",
      "   comments_disabled  draft  promoted  position  vote_sum  vote_count  ...  \\\n",
      "0               True  False     False         0         3           3  ...   \n",
      "1               True  False     False         0       -11          33  ...   \n",
      "\n",
      "   locale outdated outdated_locales             edited_at user_segment_id  \\\n",
      "0   en-us    False               []  2024-05-29T15:15:07Z             NaN   \n",
      "1   en-us    False               []  2024-05-14T18:58:22Z             NaN   \n",
      "\n",
      "  permission_group_id content_tag_ids  label_names  \\\n",
      "0              997491              []           []   \n",
      "1              997471              []           []   \n",
      "\n",
      "                                                body user_segment_ids  \n",
      "0  <p class=\"wysiwyg-text-align-left\"><img src=\"h...               []  \n",
      "1  <p>To provide you with even better support reg...               []  \n",
      "\n",
      "[2 rows x 26 columns]\n",
      "Missing values:\n",
      "[('user_segment_id', 165)]\n"
     ]
    }
   ],
   "source": [
    "# First, we'll do some basic checking of the data\n",
    "# things like column shape, column names, some of the first rows, see if there are any missing values\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(f\"Number of articles: {df.shape[0]}\")\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"First two rows of the dataset:\")\n",
    "print(df[:2])\n",
    "print(\"Missing values:\")\n",
    "print([(column, count) for column, count in df.isnull().sum().items() if count > 0])  # only show columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok cool, we did some basic EDA. Seems like a lot of columns, so the first thing we should do is try to reduce the number of columns as they will be the features of our unsupervised ML model. It also looks like the `body` column has HTML which would not be helpful for a Topic Modelling algorithm. Though it is possible that HTML with higher importance (like an H1 tag vs an H6 tag) could be more important, I think we would need to use a neural network for the model to train on the difference, and an unsupervised algorithm like LDA would not be able to work well with those nuances.\n",
    "\n",
    "Even though we will probably end up using the LDA algorithm and use a combination of the title and the body features, we should still perform some kind of EDA in case we decide to use different algorithms that will make use of other features. \n",
    "\n",
    "So first EDA procedure we will be to remove columns that will provide no value: \n",
    "1. Remove unused columns (columns with nan)\n",
    "2. Remove columns that are only provide an id\n",
    "3. Remove columns that only have one unique value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns before cleaning: 13\n",
      "Number of columns before cleaning: 13\n",
      "Columns after cleaning: ['url', 'html_url', 'promoted', 'position', 'vote_sum', 'vote_count', 'created_at', 'updated_at', 'name', 'title', 'edited_at', 'label_names', 'body']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>promoted</th>\n",
       "      <th>position</th>\n",
       "      <th>vote_sum</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>edited_at</th>\n",
       "      <th>label_names</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://amboss.zendesk.com/api/v2/help_center/...</td>\n",
       "      <td>https://support.amboss.com/hc/en-us/articles/2...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-28T12:12:18Z</td>\n",
       "      <td>2024-05-29T15:15:11Z</td>\n",
       "      <td>NEJM Knowledge+ and AMBOSS</td>\n",
       "      <td>NEJM Knowledge+ and AMBOSS</td>\n",
       "      <td>2024-05-29T15:15:07Z</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;p class=\"wysiwyg-text-align-left\"&gt;&lt;img src=\"h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://amboss.zendesk.com/api/v2/help_center/...</td>\n",
       "      <td>https://support.amboss.com/hc/en-us/articles/1...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-11</td>\n",
       "      <td>33</td>\n",
       "      <td>2023-06-15T14:45:07Z</td>\n",
       "      <td>2024-05-14T18:58:27Z</td>\n",
       "      <td>ðŸ¤– Virtual AMBOSS Assistant (Beta)</td>\n",
       "      <td>ðŸ¤– Virtual AMBOSS Assistant (Beta)</td>\n",
       "      <td>2024-05-14T18:58:22Z</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;p&gt;To provide you with even better support reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://amboss.zendesk.com/api/v2/help_center/...</td>\n",
       "      <td>https://support.amboss.com/hc/en-us/articles/1...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-05-31T11:35:58Z</td>\n",
       "      <td>2024-04-26T13:20:30Z</td>\n",
       "      <td>Program Overview</td>\n",
       "      <td>Program Overview</td>\n",
       "      <td>2024-04-26T13:20:23Z</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;p&gt;AMBOSS is accredited by the Accreditation C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://amboss.zendesk.com/api/v2/help_center/...</td>\n",
       "      <td>https://support.amboss.com/hc/en-us/articles/1...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-14</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-02-01T13:49:56Z</td>\n",
       "      <td>2024-04-29T15:14:04Z</td>\n",
       "      <td>Access to Anki Mobile Support (Beta)</td>\n",
       "      <td>Access to Anki Mobile Support (Beta)</td>\n",
       "      <td>2023-10-05T14:50:48Z</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Anki Mobile Support (Beta)&lt;/strong&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://amboss.zendesk.com/api/v2/help_center/...</td>\n",
       "      <td>https://support.amboss.com/hc/en-us/articles/1...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-26T12:59:53Z</td>\n",
       "      <td>2024-04-26T16:19:24Z</td>\n",
       "      <td>Persistent Filters</td>\n",
       "      <td>Persistent Filters</td>\n",
       "      <td>2023-10-06T13:39:25Z</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;div class=\"p-rich_text_section\"&gt;Creating aÂ &lt;s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://amboss.zendesk.com/api/v2/help_center/...   \n",
       "1  https://amboss.zendesk.com/api/v2/help_center/...   \n",
       "2  https://amboss.zendesk.com/api/v2/help_center/...   \n",
       "3  https://amboss.zendesk.com/api/v2/help_center/...   \n",
       "4  https://amboss.zendesk.com/api/v2/help_center/...   \n",
       "\n",
       "                                            html_url  promoted  position  \\\n",
       "0  https://support.amboss.com/hc/en-us/articles/2...     False         0   \n",
       "1  https://support.amboss.com/hc/en-us/articles/1...     False         0   \n",
       "2  https://support.amboss.com/hc/en-us/articles/1...     False         0   \n",
       "3  https://support.amboss.com/hc/en-us/articles/1...     False         0   \n",
       "4  https://support.amboss.com/hc/en-us/articles/1...     False         0   \n",
       "\n",
       "   vote_sum  vote_count            created_at            updated_at  \\\n",
       "0         3           3  2024-03-28T12:12:18Z  2024-05-29T15:15:11Z   \n",
       "1       -11          33  2023-06-15T14:45:07Z  2024-05-14T18:58:27Z   \n",
       "2         3           5  2023-05-31T11:35:58Z  2024-04-26T13:20:30Z   \n",
       "3       -14          14  2023-02-01T13:49:56Z  2024-04-29T15:14:04Z   \n",
       "4         3           3  2023-01-26T12:59:53Z  2024-04-26T16:19:24Z   \n",
       "\n",
       "                                   name                                 title  \\\n",
       "0            NEJM Knowledge+ and AMBOSS            NEJM Knowledge+ and AMBOSS   \n",
       "1     ðŸ¤– Virtual AMBOSS Assistant (Beta)     ðŸ¤– Virtual AMBOSS Assistant (Beta)   \n",
       "2                      Program Overview                      Program Overview   \n",
       "3  Access to Anki Mobile Support (Beta)  Access to Anki Mobile Support (Beta)   \n",
       "4                    Persistent Filters                    Persistent Filters   \n",
       "\n",
       "              edited_at label_names  \\\n",
       "0  2024-05-29T15:15:07Z          []   \n",
       "1  2024-05-14T18:58:22Z          []   \n",
       "2  2024-04-26T13:20:23Z          []   \n",
       "3  2023-10-05T14:50:48Z          []   \n",
       "4  2023-10-06T13:39:25Z          []   \n",
       "\n",
       "                                                body  \n",
       "0  <p class=\"wysiwyg-text-align-left\"><img src=\"h...  \n",
       "1  <p>To provide you with even better support reg...  \n",
       "2  <p>AMBOSS is accredited by the Accreditation C...  \n",
       "3  <p><strong>Anki Mobile Support (Beta)</strong>...  \n",
       "4  <div class=\"p-rich_text_section\">Creating aÂ <s...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, let's count how many columns we are starting with\n",
    "print(f\"Number of columns before cleaning: {len(df.columns)}\")\n",
    "\n",
    "#drop columns with missing values or empty arrays\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# remove columns that only provide id if they exist\n",
    "id_columns = ['id', 'author_id', 'section_id', 'permission_group_id', 'content_tag_ids']\n",
    "for column in id_columns:\n",
    "    if column in df.columns:\n",
    "        df = df.drop(column, axis=1)\n",
    "\n",
    "# check if all comments are disable, which means the feature / column doesn't provide value \n",
    "if 'comments_disabled' in df.columns:\n",
    "    all_comments_disabled = df[~df['comments_disabled'] == 'True']\n",
    "    if len(all_comments_disabled) == 0:\n",
    "        df = df.drop(['comments_disabled'], axis=1)\n",
    "        print(\"All comments are disabled. Dropping column.\")\n",
    "    \n",
    "# Now, let's check if any other columns only have the same value, then drop them too\n",
    "for column in df.columns:\n",
    "    if df[column].nunique() == 1:\n",
    "        print(f\"Column {column} has only one unique value of {df[column].iloc[0]}. Dropping it.\")\n",
    "        df = df.drop(column, axis=1)\n",
    "        \n",
    "print(f\"Number of columns before cleaning: {len(df.columns)}\")\n",
    "print(\"Columns after cleaning:\", df.columns.tolist())\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed 10 columns -> from 26 to 13, which is a great start to the EDA process. After reviewing the columns and the data now that there are less columns, it's more clear that the two columns that would provide the most value to an unsupervised algorithm that will categorize a help center article is the `title` and `body`. So let's drop all the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['url', 'html_url', 'promoted', 'position', 'vote_sum', 'vote_count', 'created_at', 'updated_at', 'name', 'edited_at', 'label_names']\n",
      "Columns after dropping: ['title', 'body']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [column for column in df.columns.to_list() if column not in ['title','body']]\n",
    "print(f\"Dropping columns: {columns_to_drop}\")\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "print(\"Columns after dropping:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great - now we only have two columns to look at. We spoke before about removing HTML, and the `body` column has HTML, so let's remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "df['body'] = df['body'].apply(strip_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEJM Knowledge+ and AMBOSS</td>\n",
       "      <td>The New England Journal of Medicine launched N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ðŸ¤– Virtual AMBOSS Assistant (Beta)</td>\n",
       "      <td>To provide you with even better support regard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Program Overview</td>\n",
       "      <td>AMBOSS is accredited by the Accreditation Coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access to Anki Mobile Support (Beta)</td>\n",
       "      <td>Anki Mobile Support (Beta) has been rolled out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Persistent Filters</td>\n",
       "      <td>Creating aÂ Custom Qbank session allows you to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0            NEJM Knowledge+ and AMBOSS   \n",
       "1     ðŸ¤– Virtual AMBOSS Assistant (Beta)   \n",
       "2                      Program Overview   \n",
       "3  Access to Anki Mobile Support (Beta)   \n",
       "4                    Persistent Filters   \n",
       "\n",
       "                                                body  \n",
       "0  The New England Journal of Medicine launched N...  \n",
       "1  To provide you with even better support regard...  \n",
       "2  AMBOSS is accredited by the Accreditation Coun...  \n",
       "3  Anki Mobile Support (Beta) has been rolled out...  \n",
       "4  Creating aÂ Custom Qbank session allows you to ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have chosen our important columns, let's do some data analysis on the textual data in the body and the title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

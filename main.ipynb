{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description / Topic Modelling\n",
    "\n",
    "We will use a unsupervised machine learning algorithm to categorize Customer Support help center articles - also known as **Topic Modelling**. The problem we are trying to solve is that searching a few hundred help center article has a better user experience when you can use tags to find articles that matter to you. This will also be used for search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Gather data\n",
    "\n",
    "\n",
    "I'll create a function that will download the text from a specific help center that uses Zendesk (A SaaS). We check if the data already exists at `data/articles.csv`, if it does then we don't get the data again. \n",
    "\n",
    "Since each help center is related to one specific business, we will only process one companies help center instead of processing many help center. This will allow our Topic Modelling model(s) to be more accurate for each specific business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def fetch_articles():\n",
    "    url = \"https://support.amboss.com/api/v2/help_center/en-us/articles?per_page=100\"\n",
    "    all_articles = []\n",
    "\n",
    "    while url:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        all_articles.extend(data['articles'])\n",
    "        url = data.get('next_page')\n",
    "\n",
    "    return all_articles\n",
    "\n",
    "def save_articles_to_csv(articles, filename):\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "file_path = 'data/articles.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    articles = fetch_articles()\n",
    "    save_articles_to_csv(articles, file_path)\n",
    "    print(f\"Articles saved to {file_path}\")\n",
    "else:\n",
    "    print(f\"File {file_path} already exists. Skipping data collection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Identify an Unsupervised Learning Problem\n",
    "\n",
    "For categorizing / labelling a relatively large amount (100+) customer support help center articles, we will use Topic Modelling (and most likely Latent Dirichlet Allocation) as the unsupervised learning algorithm because we don't have labels on the existing customer support help center articles. In addition, we are an external team, so we won't have the knowledge needed to manually label the data. Some other reasons we will use that unsupervised learning algorithm:\n",
    "* It can discover latent features well within a collection of documents.\n",
    "* Topic Modelling works well with unstructured text.\n",
    "* It can handle new and update help center articles well - since the information on a support help center changes often, we want a scalable solution. \n",
    "* It is also flexible, and will be able to find latent features in any new informmation that is provided in the help center articles. \n",
    "* It can condense the high dimensionaility of words into a lower dimension topics, which will make it easier to analyze the overall themes.\n",
    "\n",
    "Using a supervised machine learning algorithm is not ideal because we don't have labelled data and we want this solution to be scalable. We want to be able to handle new topics without needing to re-fit or label our data - otherwise a supervised algorithm will be considered overfit if we don't re-train the model when new topics or themes in the support help center are introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - EDA\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
